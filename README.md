# Project title: Inclusive Computer Vision â€” Towards Bias-Aware and Fair Recognition Systems

## Short description: 
Reproducible pipeline for dataset curation, fairness-conscious training (sample reweighting, adversarial debiasing), and post-hoc explainability (Grad-CAM) to reduce demographic bias in face recognition. Includes three experiment configs: male-biased, female-biased, and balanced fairness-aware models.

## Key results 

- Balanced fairness-aware model: 87.16% validation accuracy; male accuracy 86.3%, female 88.1% (gap < 2%).

- Male-biased model: 84.33% validation; subgroup gap > 10 pts.

- Female-biased model: 85.28% validation; subgroup gap > 10 pts.
